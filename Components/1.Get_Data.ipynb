{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e8bc2c",
   "metadata": {},
   "source": [
    "# This is how we get and organize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797439b9",
   "metadata": {},
   "source": [
    "# Get NC4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9ca4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime as dt \n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import requests\n",
    "import glob\n",
    "\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa675e",
   "metadata": {},
   "source": [
    "# Open 1 Nc4 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28a54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 264kB\n",
      "Dimensions:     (Latitude: 180, Longitude: 360)\n",
      "Coordinates:\n",
      "  * Longitude   (Longitude) float64 3kB -180.0 -179.0 -178.0 ... 178.0 179.0\n",
      "  * Latitude    (Latitude) float64 1kB 90.0 89.0 88.0 87.0 ... -87.0 -88.0 -89.0\n",
      "Data variables:\n",
      "    CloudFrc_A  (Latitude, Longitude) float32 259kB ...\n",
      "Attributes: (12/420)\n",
      "    HDFEOSVersion:                                        HDFEOS_V2.18\n",
      "    identifier_product_doi:                               10.5067/UBENJB9D3T2H\n",
      "    identifier_product_doi_authority:                     http://dx.doi.org/\n",
      "    history:                                              2025-10-05 17:50:51...\n",
      "    history_json:                                         [{\"$schema\":\"https:...\n",
      "    ascending._FV_TotalCounts_A:                          -9999.0\n",
      "    ...                                                   ...\n",
      "    location.H2OPressureLev:                              1000.0\n",
      "    location.H2OPressureLay:                              961.7692\n",
      "    location.EmisFreqIR:                                  832.0\n",
      "    location.EmisFreqMW:                                  23.8\n",
      "    location.CoarseCloudLayer:                            865.0\n",
      "    location.FineCloudLayer:                              1018.0\n"
     ]
    }
   ],
   "source": [
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset(r\"C:\\Users\\LENOVO\\Downloads\\AIRS.2025.05.01.L3.RetStd_IR031.v7.0.7.0.G25188113435.hdf.nc4\")\n",
    "\n",
    "print(ds)  # shows variables, dimensions, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb74734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: ['CloudFrc_A', 'Longitude', 'Latitude']\n"
     ]
    }
   ],
   "source": [
    "# show just the variable names\n",
    "print(\"Variables:\", list(ds.variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1796d206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CloudFrc_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>0.052002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>0.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-178.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>0.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>0.226562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude  CloudFrc_A\n",
       "0      90.0     -180.0    0.052002\n",
       "1      90.0     -179.0    0.609375\n",
       "2      90.0     -178.0    0.000000\n",
       "3      90.0     -177.0    0.431641\n",
       "4      90.0     -176.0    0.226562"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a DataFrame (flattened)\n",
    "df = ds.to_dataframe().reset_index()\n",
    "df.head() # show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd128239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728000, 6)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417105c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                0\n",
      "bnds                0\n",
      "lon                 0\n",
      "lat                 0\n",
      "time_bnds           0\n",
      "Swnet_tavg    1242494\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35682be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'xco2' (sounding_id: 933)> Size: 4kB\n",
      "[933 values with dtype=float32]\n",
      "Coordinates:\n",
      "    longitude    (sounding_id) float32 4kB ...\n",
      "    latitude     (sounding_id) float32 4kB ...\n",
      "  * sounding_id  (sounding_id) float64 7kB 2.009e+13 2.009e+13 ... 2.009e+13\n",
      "Attributes:\n",
      "    units:      ppm\n",
      "    long_name:  XCO2\n",
      "    comment:    Column-averaged dry-air mole fraction of CO2 (includes bias c...\n"
     ]
    }
   ],
   "source": [
    "# Access a variable (e.g., \"CO2\")\n",
    "co2 = ds[\"xco2\"]\n",
    "print(co2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858f8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\Co2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00df3c",
   "metadata": {},
   "source": [
    "# Merge NC4 to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16359bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 files\n",
      "Processing GLDAS_NOAH10_M.A202301.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202302.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202303.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202304.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202305.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202306.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202307.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202308.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202309.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202310.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202311.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202312.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202401.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202402.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202403.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202404.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202405.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202406.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202407.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202408.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202409.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202410.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202411.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202412.021.nc4.SUB.nc4\n",
      "‚úÖ Merged shape: (1296000, 4)\n",
      "üíæ Saved to merged_SWnet_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Folder containing your .nc4 files\n",
    "folder = r\"C:\\Users\\LENOVO\\Downloads\\NetShortwave\" # change to your folder path\n",
    "\n",
    "# 2Ô∏è‚É£ Find all .nc4 files in that folder\n",
    "files = sorted(glob.glob(os.path.join(folder, \"*.nc4\")))\n",
    "print(f\"Found {len(files)} files\")\n",
    "\n",
    "# 3Ô∏è‚É£ Store all dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# 4Ô∏è‚É£ Loop through files\n",
    "for f in files:\n",
    "    try:\n",
    "        ds = xr.open_dataset(f)\n",
    "        print(f\"Processing {os.path.basename(f)}\")\n",
    "\n",
    "        # Extract only desired columns\n",
    "        df = ds[].to_dataframe().reset_index()\n",
    "\n",
    "        # Optional: drop duplicates or NaN if any\n",
    "        #df = df.dropna(subset=[\"SWnet\"])\n",
    "\n",
    "        all_dfs.append(df)\n",
    "        ds.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {f}: {e}\")\n",
    "\n",
    "# 5Ô∏è‚É£ Merge all DataFrames\n",
    "if all_dfs:\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"‚úÖ Merged shape: {merged_df.shape}\")\n",
    "\n",
    "    # 6Ô∏è‚É£ Export to CSV\n",
    "    merged_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\Except_Cloud.csv\", index=False)\n",
    "    print(\"üíæ Saved to merged_SWnet_data.csv\")\n",
    "else:\n",
    "    print(\"‚ùå No data to merge ‚Äî check your files or variable names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1f5cb",
   "metadata": {},
   "source": [
    "### Export the entire CSV all Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4948535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nlon   nlat  nlayer  surfacePrecipitation  surfaceRain  \\\n",
      "0 -179.75 -39.75     0.5                   NaN          NaN   \n",
      "1 -179.75 -39.75     1.0                   NaN          NaN   \n",
      "2 -179.75 -39.75     1.5                   NaN          NaN   \n",
      "3 -179.75 -39.75     2.0                   NaN          NaN   \n",
      "4 -179.75 -39.75     2.5                   NaN          NaN   \n",
      "\n",
      "   convectPrecipitation  cldWater  rainWater  cldIce  snow  graupel  \\\n",
      "0                   NaN       NaN        NaN     NaN   NaN      NaN   \n",
      "1                   NaN       NaN        NaN     NaN   NaN      NaN   \n",
      "2                   NaN       NaN        NaN     NaN   NaN      NaN   \n",
      "3                   NaN       NaN        NaN     NaN   NaN      NaN   \n",
      "4                   NaN       NaN        NaN     NaN   NaN      NaN   \n",
      "\n",
      "   latentHeat  npixTotal  npixPrecipitation  fractionQuality0  \\\n",
      "0         NaN        0.0                0.0               NaN   \n",
      "1         NaN        0.0                0.0               NaN   \n",
      "2         NaN        0.0                0.0               NaN   \n",
      "3         NaN        0.0                0.0               NaN   \n",
      "4         NaN        0.0                0.0               NaN   \n",
      "\n",
      "   fractionQuality1  fractionQuality2  \n",
      "0               NaN               NaN  \n",
      "1               NaN               NaN  \n",
      "2               NaN               NaN  \n",
      "3               NaN               NaN  \n",
      "4               NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# (assuming you already opened ds)\n",
    "ds = xr.open_dataset(r\"C:\\Users\\LENOVO\\Downloads\\3A12.20150301.7.HDF.nc4\")\n",
    "\n",
    "# Convert all variables into a DataFrame\n",
    "df = ds.to_dataframe().reset_index()\n",
    "\n",
    "# Show first few rows\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e0b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263fdc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: ['nlon', 'nlat', 'nlayer', 'surfacePrecipitation', 'surfaceRain', 'convectPrecipitation', 'cldWater', 'rainWater', 'cldIce', 'snow', 'graupel', 'latentHeat', 'npixTotal', 'npixPrecipitation', 'fractionQuality0', 'fractionQuality1', 'fractionQuality2']\n"
     ]
    }
   ],
   "source": [
    "# show just the variable names\n",
    "print(\"Variables:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NC4 is a very large so filter\n",
    "df_small = df[[\"latitude\", \"longitude\", \"time\", \"xco2\", \"xco2_uncertainty\"]]\n",
    "df_small.to_csv(r\"D:\\Hackathon\\Dataset\\ACOS & OCO\\ACOS\\Acos_co2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read_csv\n",
    "df = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\Acos_Co2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08937ea2",
   "metadata": {},
   "source": [
    "# Automate download data and merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf4eb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Error processing https://docserver.gesdisc.eosdis.nasa.gov/public/project/hydrology/README_GLDAS2.pdf: ValueError - did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\n",
      "https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\n",
      "https://docs.xarray.dev/en/stable/user-guide/io.html\n",
      "üì• Downloading 2/25: https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202301.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202301.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg\n",
      "‚ö†Ô∏è Error processing https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202301.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202301.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg: FileNotFoundError - [Errno 2] No such file or directory: 'C:\\\\Users\\\\LENOVO\\\\Downloads\\\\Rain&Snow\\\\HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202301.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202301.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg'\n",
      "üì• Downloading 3/25: https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202302.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202302.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg\n",
      "‚ö†Ô∏è Error processing https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202302.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202302.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg: FileNotFoundError - [Errno 2] No such file or directory: 'C:\\\\Users\\\\LENOVO\\\\Downloads\\\\Rain&Snow\\\\HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202302.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202302.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg'\n",
      "üì• Downloading 4/25: https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202303.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202303.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg\n",
      "‚ö†Ô∏è Error processing https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202303.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202303.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg: FileNotFoundError - [Errno 2] No such file or directory: 'C:\\\\Users\\\\LENOVO\\\\Downloads\\\\Rain&Snow\\\\HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202303.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202303.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg'\n",
      "üì• Downloading 5/25: https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FGLDAS%2FGLDAS_NOAH025_M.2.1%2F2023%2FGLDAS_NOAH025_M.A202304.021.nc4&VERSION=1.02&FORMAT=bmM0Lw&BBOX=-60%2C-180%2C90%2C180&SHORTNAME=GLDAS_NOAH025_M&DATASET_VERSION=2.1&SERVICE=L34RS_LDAS&LABEL=GLDAS_NOAH025_M.A202304.021.nc4.SUB.nc4&VARIABLES=Rainf_f_tavg%2CSnowf_tavg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filename):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müì• Downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(links)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     31\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    645\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    646\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    647\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    648\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    649\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    650\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    651\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    652\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    653\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    654\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    655\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    656\u001b[0m     )\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ Paths\n",
    "links_file = r\"C:\\Users\\LENOVO\\Downloads\\Rain&SnowList.txt\"\n",
    "download_dir = r\"C:\\Users\\LENOVO\\Downloads\\Rain&Snow\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# 2Ô∏è‚É£ NASA Earthdata token\n",
    "token = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImtpZXRkYXRhY3V0ZSIsImV4cCI6MTc2NDg1NzQ4NywiaWF0IjoxNzU5NjczNDg3LCJpc3MiOiJodHRwczovL3Vycy5lYXJ0aGRhdGEubmFzYS5nb3YiLCJpZGVudGl0eV9wcm92aWRlciI6ImVkbF9vcHMiLCJhY3IiOiJlZGwiLCJhc3N1cmFuY2VfbGV2ZWwiOjN9.prA4yN8UfzIAFYyJ5HLaYg-_MWCGJ72pT89NVpXy9iTUNeh431WGdwAglnC9T3Cr7MkYgEisSmalksN3HoHuruZs06oPyTp0IycGh9lQio8sozZSTtdtp8oI_p5IVhSHasM6X4EtbMQpLwxXfMDsaliAKLbYPH4Nytmr04ezwID9uyWtmy5Y6AesyUZ7zCtaoFcmgPAfn__oYhu133yW_9WIsQYx8Xs1HZgyvMNB7q2cYAfITX5RP2ZbPiFJRDaZUXEe5VplM4t5ZluOOnNJabHvm3J5mCJ98VSuFvhbyhzdhVQHq_G8pN_jfMmDBe63jogWZx-HBuxaRSsNRE3uiA\"  # üëà paste your token\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "# 3Ô∏è‚É£ Read link\n",
    "with open(links_file, \"r\") as f:\n",
    "    links = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# 4Ô∏è‚É£ Loop through each link\n",
    "for i, url in enumerate(links, 1):\n",
    "    try:\n",
    "        filename = os.path.join(download_dir, os.path.basename(url))\n",
    "\n",
    "        # --- download if not already ---\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"üì• Downloading {i}/{len(links)}: {url}\")\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "        # --- open dataset ---\n",
    "        ds = xr.open_dataset(filename)\n",
    "\n",
    "        # --- extract key variables ---\n",
    "        df = ds[['time', 'time_bnds', 'lon', 'lat', 'Snowf_tavg', 'Rainf_f_tavg']].to_dataframe().reset_index()\n",
    "\n",
    "        all_data.append(df)\n",
    "        ds.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {url}: {type(e).__name__} - {e}\")\n",
    "\n",
    "# 5Ô∏è‚É£ Combine all datasets\n",
    "if all_data:\n",
    "    merged_df = pd.concat(all_data, ignore_index=True)\n",
    "    merged_df.to_csv(\"oco2_combined.csv\", index=False)\n",
    "    print(\"‚úÖ Done! Saved as 'oco2_combined.csv'\")\n",
    "else:\n",
    "    print(\"‚ùå No data was successfully loaded. Check your token or network.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03135c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! Saved as 'oco2_combined.csv'\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ Combine all daily datasets\n",
    "merged_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 6Ô∏è‚É£ Export to CSV\n",
    "merged_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\co2.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Done! Saved as 'oco2_combined.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eeee24",
   "metadata": {},
   "source": [
    "# CDF File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fde886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 839kB\n",
      "Dimensions:   (time: 1, lon: 576, lat: 361)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 8B 2023-01-01\n",
      "  * lon       (lon) float64 5kB -180.0 -179.4 -178.8 ... 178.1 178.8 179.4\n",
      "  * lat       (lat) float64 3kB -90.0 -89.5 -89.0 -88.5 ... 88.5 89.0 89.5 90.0\n",
      "Data variables:\n",
      "    SPEEDLML  (time, lat, lon) float32 832kB ...\n",
      "Attributes: (12/32)\n",
      "    CDI:                               Climate Data Interface version 1.9.8 (...\n",
      "    Conventions:                       CF-1\n",
      "    Contact:                           http://gmao.gsfc.nasa.gov\n",
      "    History:                           Original file generated: Sun Feb 12 02...\n",
      "    Filename:                          MERRA2_400.instM_2d_lfo_Nx.202301.nc4\n",
      "    Comment:                           GMAO filename: d5124_m2_jan10.inst1_2d...\n",
      "    ...                                ...\n",
      "    DataResolution:                    0.5 x 0.625\n",
      "    identifier_product_doi:            10.5067/11F99Y6TXN99\n",
      "    RangeBeginningTime:                00:00:00.000000\n",
      "    RangeEndingTime:                   23:00:00.000000\n",
      "    history_L34RS:                     'Created by L34RS v1.4.4 @ NASA GES DI...\n",
      "    CDO:                               Climate Data Operators version 1.9.8 (...\n"
     ]
    }
   ],
   "source": [
    "# Path to your file\n",
    "file_path = r\"C:\\Users\\LENOVO\\Downloads\\WindSpeed\\MERRA2_400.instM_2d_lfo_Nx.202301.SUB.nc\"\n",
    "\n",
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Display dataset info\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e69073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: ['time', 'lon', 'lat', 'SPEEDLML']\n"
     ]
    }
   ],
   "source": [
    "#see the variables\n",
    "print(\"Variables:\", list(ds.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac6e7e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>SPEEDLML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>5.493866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-89.5</td>\n",
       "      <td>4.914066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>4.676849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-88.5</td>\n",
       "      <td>5.066791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>6.082662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time    lon   lat  SPEEDLML\n",
       "0 2023-01-01 -180.0 -90.0  5.493866\n",
       "1 2023-01-01 -180.0 -89.5  4.914066\n",
       "2 2023-01-01 -180.0 -89.0  4.676849\n",
       "3 2023-01-01 -180.0 -88.5  5.066791\n",
       "4 2023-01-01 -180.0 -88.0  6.082662"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change into dataframe\n",
    "df = ds.to_dataframe().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10119515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b80428d",
   "metadata": {},
   "source": [
    "## Merge all CDF file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd23048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 24 files\n",
      "‚úÖ Saved merged_cloud_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Folder containing your .nc files\n",
    "folder = r\"C:\\Users\\LENOVO\\Downloads\\AirTemp\"\n",
    "\n",
    "# Step 1: Find all .nc or .nc4 files in the folder\n",
    "files = glob.glob(os.path.join(folder, \"*.nc\")) + glob.glob(os.path.join(folder, \"*.nc4\"))\n",
    "\n",
    "print(f\"‚úÖ Found {len(files)} files\")\n",
    "\n",
    "# Step 2: Open and combine them\n",
    "ds = xr.open_mfdataset(files, combine='by_coords')\n",
    "\n",
    "# Step 3: Convert to DataFrame and save\n",
    "df = ds.to_dataframe().reset_index()\n",
    "df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\AirTemp.csv\", index=False)\n",
    "print(\"‚úÖ Saved merged_cloud_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f81e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f387f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e68a6d",
   "metadata": {},
   "source": [
    "# Fix the spatial resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7da1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>CLDTOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0000</td>\n",
       "      <td>-89.75</td>\n",
       "      <td>0.497406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0000</td>\n",
       "      <td>-89.00</td>\n",
       "      <td>0.554248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0000</td>\n",
       "      <td>-88.00</td>\n",
       "      <td>0.542849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0000</td>\n",
       "      <td>-87.00</td>\n",
       "      <td>0.502070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-180.0000</td>\n",
       "      <td>-86.00</td>\n",
       "      <td>0.459127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563835</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>179.0625</td>\n",
       "      <td>86.00</td>\n",
       "      <td>0.966063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563836</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>179.0625</td>\n",
       "      <td>87.00</td>\n",
       "      <td>0.950423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563837</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>179.0625</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.937046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563838</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>179.0625</td>\n",
       "      <td>89.00</td>\n",
       "      <td>0.955067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563839</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>179.0625</td>\n",
       "      <td>89.75</td>\n",
       "      <td>0.966313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1563840 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time       lon    lat    CLDTOT\n",
       "0        2023-01-01 -180.0000 -89.75  0.497406\n",
       "1        2023-01-01 -180.0000 -89.00  0.554248\n",
       "2        2023-01-01 -180.0000 -88.00  0.542849\n",
       "3        2023-01-01 -180.0000 -87.00  0.502070\n",
       "4        2023-01-01 -180.0000 -86.00  0.459127\n",
       "...             ...       ...    ...       ...\n",
       "1563835  2024-12-01  179.0625  86.00  0.966063\n",
       "1563836  2024-12-01  179.0625  87.00  0.950423\n",
       "1563837  2024-12-01  179.0625  88.00  0.937046\n",
       "1563838  2024-12-01  179.0625  89.00  0.955067\n",
       "1563839  2024-12-01  179.0625  89.75  0.966313\n",
       "\n",
       "[1563840 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Open the cloud dataset\n",
    "cloud_ds = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\Cloud.csv\")  # replace with your file\n",
    "# Assume cloud variable is 'CloudFrc'\n",
    "\n",
    "# Create 1¬∞ bins for lon and lat\n",
    "cloud_ds['lon_bin'] = np.round(cloud_ds['lon'])\n",
    "cloud_ds['lat_bin'] = np.round(cloud_ds['lat'])\n",
    "\n",
    "# Group by the new 1¬∞ bins and take the mean\n",
    "cloud_agg = cloud_ds.groupby(['time', 'lon_bin', 'lat_bin']).mean()\n",
    "\n",
    "# Rename bins to standard lon/lat for merging\n",
    "cloud_agg = cloud_agg.rename({'lon_bin': 'lon', 'lat_bin': 'lat'})\n",
    "\n",
    "# Convert to DataFrame if needed\n",
    "cloud_agg_df = cloud_agg.reset_index()\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "cloud_agg_df['time'] = pd.to_datetime(cloud_agg_df['time']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Keep only the needed columns\n",
    "cloud_agg_df = cloud_agg_df[['time', 'lon', 'lat', 'CLDTOT']]\n",
    "\n",
    "# Display result\n",
    "cloud_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fd548fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "cloud_agg_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\Cloud1X1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a2408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c59989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707fbf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed61db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6310875",
   "metadata": {},
   "source": [
    "# merge NC4 into CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3567cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 files\n",
      "Processing GLDAS_NOAH10_M.A202301.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202302.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202303.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202304.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202305.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202306.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202307.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202308.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202309.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202310.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202311.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202312.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202401.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202402.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202403.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202404.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202405.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202406.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202407.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202408.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202409.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202410.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202411.021.nc4.SUB.nc4\n",
      "Processing GLDAS_NOAH10_M.A202412.021.nc4.SUB.nc4\n",
      "‚úÖ Merged shape: (2592000, 10)\n",
      "üíæ Saved to merged_SWnet_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Folder containing your .nc4 files\n",
    "folder = r\"C:\\Users\\LENOVO\\Downloads\\All_except_Cloud\" # change to your folder path\n",
    "\n",
    "# 2Ô∏è‚É£ Find all .nc4 files in that folder\n",
    "files = sorted(glob.glob(os.path.join(folder, \"*.nc4\")))\n",
    "print(f\"Found {len(files)} files\")\n",
    "\n",
    "# 3Ô∏è‚É£ Store all dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# 4Ô∏è‚É£ Loop through files\n",
    "for f in files:\n",
    "    try:\n",
    "        ds = xr.open_dataset(f)\n",
    "        print(f\"Processing {os.path.basename(f)}\")\n",
    "\n",
    "        # Extract only desired columns\n",
    "        df = ds[['time', 'time_bnds', 'lon', 'lat', 'Swnet_tavg', 'Snowf_tavg', 'Rainf_tavg', 'Wind_f_inst', 'Tair_f_inst']].to_dataframe().reset_index()\n",
    "\n",
    "        # Optional: drop duplicates or NaN if any\n",
    "        #df = df.dropna(subset=[\"SWnet\"])\n",
    "\n",
    "        all_dfs.append(df)\n",
    "        ds.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {f}: {e}\")\n",
    "\n",
    "# 5Ô∏è‚É£ Merge all DataFrames\n",
    "if all_dfs:\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"‚úÖ Merged shape: {merged_df.shape}\")\n",
    "\n",
    "    # 6Ô∏è‚É£ Export to CSV\n",
    "    merged_df.to_csv(r\"C:\\Users\\LENOVO\\Downloads\\Except_Cloud.csv\", index=False)\n",
    "    print(\"üíæ Saved to merged_SWnet_data.csv\")\n",
    "else:\n",
    "    print(\"‚ùå No data to merge ‚Äî check your files or variable names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f97c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6859e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bfe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ea472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faac708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea03a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd09a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6d269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68bb417b",
   "metadata": {},
   "source": [
    "# See data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf23efa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>bnds</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time_bnds</th>\n",
       "      <th>Swnet_tavg</th>\n",
       "      <th>Snowf_tavg</th>\n",
       "      <th>Rainf_tavg</th>\n",
       "      <th>Wind_f_inst</th>\n",
       "      <th>Tair_f_inst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>-59.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>-58.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>-57.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>-56.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>-55.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591995</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>85.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591996</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591997</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591998</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>88.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591999</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592000 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  bnds    lon   lat   time_bnds  Swnet_tavg  Snowf_tavg  \\\n",
       "0        2023-01-01     0 -179.5 -59.5  2023-01-01         NaN         NaN   \n",
       "1        2023-01-01     0 -179.5 -58.5  2023-01-01         NaN         NaN   \n",
       "2        2023-01-01     0 -179.5 -57.5  2023-01-01         NaN         NaN   \n",
       "3        2023-01-01     0 -179.5 -56.5  2023-01-01         NaN         NaN   \n",
       "4        2023-01-01     0 -179.5 -55.5  2023-01-01         NaN         NaN   \n",
       "...             ...   ...    ...   ...         ...         ...         ...   \n",
       "2591995  2024-12-01     1  179.5  85.5  2025-01-01         NaN         NaN   \n",
       "2591996  2024-12-01     1  179.5  86.5  2025-01-01         NaN         NaN   \n",
       "2591997  2024-12-01     1  179.5  87.5  2025-01-01         NaN         NaN   \n",
       "2591998  2024-12-01     1  179.5  88.5  2025-01-01         NaN         NaN   \n",
       "2591999  2024-12-01     1  179.5  89.5  2025-01-01         NaN         NaN   \n",
       "\n",
       "         Rainf_tavg  Wind_f_inst  Tair_f_inst  \n",
       "0               NaN          NaN          NaN  \n",
       "1               NaN          NaN          NaN  \n",
       "2               NaN          NaN          NaN  \n",
       "3               NaN          NaN          NaN  \n",
       "4               NaN          NaN          NaN  \n",
       "...             ...          ...          ...  \n",
       "2591995         NaN          NaN          NaN  \n",
       "2591996         NaN          NaN          NaN  \n",
       "2591997         NaN          NaN          NaN  \n",
       "2591998         NaN          NaN          NaN  \n",
       "2591999         NaN          NaN          NaN  \n",
       "\n",
       "[2592000 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\Except_Cloud.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f0d8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2023-01-01    108000\n",
       "2023-02-01    108000\n",
       "2023-03-01    108000\n",
       "2023-04-01    108000\n",
       "2023-05-01    108000\n",
       "2023-06-01    108000\n",
       "2023-07-01    108000\n",
       "2023-08-01    108000\n",
       "2023-09-01    108000\n",
       "2023-10-01    108000\n",
       "2023-11-01    108000\n",
       "2023-12-01    108000\n",
       "2024-01-01    108000\n",
       "2024-02-01    108000\n",
       "2024-03-01    108000\n",
       "2024-04-01    108000\n",
       "2024-05-01    108000\n",
       "2024-06-01    108000\n",
       "2024-07-01    108000\n",
       "2024-08-01    108000\n",
       "2024-09-01    108000\n",
       "2024-10-01    108000\n",
       "2024-11-01    108000\n",
       "2024-12-01    108000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many values in the time column group, organize by time ascending order\n",
    "df['time'].value_counts().sort_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc18a5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see data shape \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47deba3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time                 0\n",
       "bnds                 0\n",
       "lon                  0\n",
       "lat                  0\n",
       "time_bnds            0\n",
       "Swnet_tavg     1864368\n",
       "Snowf_tavg     1864368\n",
       "Rainf_tavg     1864368\n",
       "Wind_f_inst    1856400\n",
       "Tair_f_inst    1856400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94139414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 727632 entries, 126 to 2591978\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   time         727632 non-null  object \n",
      " 1   bnds         727632 non-null  int64  \n",
      " 2   lon          727632 non-null  float64\n",
      " 3   lat          727632 non-null  float64\n",
      " 4   time_bnds    727632 non-null  object \n",
      " 5   Swnet_tavg   727632 non-null  float64\n",
      " 6   Snowf_tavg   727632 non-null  float64\n",
      " 7   Rainf_tavg   727632 non-null  float64\n",
      " 8   Wind_f_inst  727632 non-null  float64\n",
      " 9   Tair_f_inst  727632 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 61.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#remove null values\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cfb51f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>bnds</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time_bnds</th>\n",
       "      <th>Swnet_tavg</th>\n",
       "      <th>Snowf_tavg</th>\n",
       "      <th>Rainf_tavg</th>\n",
       "      <th>Wind_f_inst</th>\n",
       "      <th>Tair_f_inst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.889153</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.502832</td>\n",
       "      <td>248.41788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>67.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.585806</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.091139</td>\n",
       "      <td>245.06335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.290484</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.810090</td>\n",
       "      <td>245.53134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.858478</td>\n",
       "      <td>245.66441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-178.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.018427</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.856865</td>\n",
       "      <td>246.43977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591828</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>178.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411122</td>\n",
       "      <td>249.06163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591975</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.206792</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.541325</td>\n",
       "      <td>253.86658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591976</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.845178</td>\n",
       "      <td>253.79471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591977</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>67.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.293003</td>\n",
       "      <td>250.90630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591978</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>179.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.417690</td>\n",
       "      <td>249.93416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727632 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  bnds    lon   lat   time_bnds  Swnet_tavg  Snowf_tavg  \\\n",
       "126      2023-01-01     0 -179.5  66.5  2023-01-01    0.889153    0.000012   \n",
       "127      2023-01-01     0 -179.5  67.5  2023-01-01    0.585806    0.000013   \n",
       "128      2023-01-01     0 -179.5  68.5  2023-01-01    0.290484    0.000014   \n",
       "131      2023-01-01     0 -179.5  71.5  2023-01-01    0.007903    0.000005   \n",
       "276      2023-01-01     0 -178.5  66.5  2023-01-01    1.018427    0.000012   \n",
       "...             ...   ...    ...   ...         ...         ...         ...   \n",
       "2591828  2024-12-01     1  178.5  68.5  2025-01-01    0.000000    0.000011   \n",
       "2591975  2024-12-01     1  179.5  65.5  2025-01-01    0.206792    0.000019   \n",
       "2591976  2024-12-01     1  179.5  66.5  2025-01-01    0.020513    0.000015   \n",
       "2591977  2024-12-01     1  179.5  67.5  2025-01-01    0.000000    0.000014   \n",
       "2591978  2024-12-01     1  179.5  68.5  2025-01-01    0.000000    0.000012   \n",
       "\n",
       "         Rainf_tavg  Wind_f_inst  Tair_f_inst  \n",
       "126             0.0     3.502832    248.41788  \n",
       "127             0.0     2.091139    245.06335  \n",
       "128             0.0     2.810090    245.53134  \n",
       "131             0.0     3.858478    245.66441  \n",
       "276             0.0     3.856865    246.43977  \n",
       "...             ...          ...          ...  \n",
       "2591828         0.0     1.411122    249.06163  \n",
       "2591975         0.0     3.541325    253.86658  \n",
       "2591976         0.0     3.845178    253.79471  \n",
       "2591977         0.0     2.293003    250.90630  \n",
       "2591978         0.0     1.417690    249.93416  \n",
       "\n",
       "[727632 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96c0723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2023-01-01    30318\n",
       "2023-02-01    30318\n",
       "2023-03-01    30318\n",
       "2023-04-01    30318\n",
       "2023-05-01    30318\n",
       "2023-06-01    30318\n",
       "2023-07-01    30318\n",
       "2023-08-01    30318\n",
       "2023-09-01    30318\n",
       "2023-10-01    30318\n",
       "2023-11-01    30318\n",
       "2023-12-01    30318\n",
       "2024-01-01    30318\n",
       "2024-02-01    30318\n",
       "2024-03-01    30318\n",
       "2024-04-01    30318\n",
       "2024-05-01    30318\n",
       "2024-06-01    30318\n",
       "2024-07-01    30318\n",
       "2024-08-01    30318\n",
       "2024-09-01    30318\n",
       "2024-10-01    30318\n",
       "2024-11-01    30318\n",
       "2024-12-01    30318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count time columns \n",
    "df['time'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0355acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
